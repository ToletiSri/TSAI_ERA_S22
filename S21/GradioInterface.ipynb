{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "347262ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from gpt import GPTLanguageModel\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "01a8318b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import config as cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "12eef6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(1337)\n",
    "\n",
    "# wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# here are all the unique characters that occur in this text\n",
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "# create a mapping from characters to integers\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s: [stoi[c] for c in s] # encoder: take a string, output a list of integers\n",
    "decode = lambda l: ''.join([itos[i] for i in l]) # decoder: take a list of integers, output a string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7b4efb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPTLanguageModel(vocab_size)\n",
    "model.load_state_dict(torch.load('saved_model.pth'))\n",
    "m = model.to(cfg.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15b38b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Save the heaven doth using lawful time\n",
      "Stirr'd in the walls, senators on the wall!\n",
      "Ay, where speak frowards that sick hraven,\n",
      "As we do steph in Scotland be else?\n",
      "So far have been piled in Richard's death;\n",
      "And, Sir John Tlums, well--\n",
      "Alack-now for the county, mistren me mis--\n",
      "The not--tabes as years at once,--ball,\n",
      "Let's fault enough but done:--lot the nibat readment\n",
      "With all the wheet-bark-but, show'd, muls fond!\n",
      "Gold I bank thee, hoo, luckle bloody love!\n",
      "Ha! brike some, I'll kiss the world: do \n"
     ]
    }
   ],
   "source": [
    "context = torch.zeros((1, 1), dtype=torch.long, device=cfg.device)\n",
    "print(decode(m.generate(context, max_new_tokens=500)[0].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673abb66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7867\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7867/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------context =  tensor([[20, 43, 56, 53]], device='cuda:0')\n",
      "--------------------context =  tensor([[22, 59, 50, 47, 59, 57]], device='cuda:0')\n",
      "--------------------context =  tensor([[13, 50, 43, 62, 39, 52, 42, 43, 56]], device='cuda:0')\n",
      "--------------------context =  tensor([[34, 47, 53, 50, 43, 58, 57]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "def inference(input_context, count):\n",
    "    encoded_text = [encode(input_context)]\n",
    "    count = int(count)\n",
    "    context = torch.tensor(encoded_text, dtype=torch.long, device=cfg.device)\n",
    "     \n",
    "    print('--------------------context = ',context)\n",
    "    out_text = decode(m.generate(context, max_new_tokens=count)[0].tolist())\n",
    "    return out_text\n",
    "\n",
    "title = \"TSAI S21 Assignment: GPT training on mini shakespeare dataset\"\n",
    "description = \"A simple Gradio interface that accepts a context and generates shakespere like text \"\n",
    "examples = [[\"Violets\",\"200\"],\n",
    "            [\"Julius\",\"200\"]\n",
    "           ]\n",
    " \n",
    "\n",
    "demo = gr.Interface(\n",
    "    inference, \n",
    "    inputs = [gr.Textbox(placeholder=\"Enter starting characters\"), gr.Textbox(placeholder=\"Enter number of characters you want to generate\")], \n",
    "    outputs = [gr.Textbox(label=\"Shakespeare like generated text\")],\n",
    "    title = title,\n",
    "    description = description,\n",
    "    examples = examples\n",
    ")\n",
    "demo.launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d542ffe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([[0]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "context_act = torch.zeros((1, 1), dtype=torch.long, device=cfg.device)\n",
    "print(type(context_act))\n",
    "print(context_act)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "442e6671",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n",
      "tensor([46, 43, 50, 50, 53], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "encoded_text = encode('hello')\n",
    "context = torch.tensor(encoded_text, dtype=torch.long, device=cfg.device)\n",
    "print(type(context))\n",
    "print(context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570a1462",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
